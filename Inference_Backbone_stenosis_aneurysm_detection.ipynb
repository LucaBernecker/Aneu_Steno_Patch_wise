{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcd078",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet, preprocess_input = Classifiers.get('resnet50')\n",
    "model = efficientnet(\n",
    "    input_shape=(32, 32, 32, 1),\n",
    "    weights=None,\n",
    "    include_top=False  # Exclude the original top layer\n",
    ")\n",
    "cut_index = None\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if layer.name == 'stage4_unit1_bn1':\n",
    "        cut_index = i\n",
    "        break\n",
    "#model.summary()\n",
    "# If the layer is found, create a new model up to that layer\n",
    "if cut_index is not None:\n",
    "    model = Model(inputs=model.input, outputs=model.layers[cut_index].output)\n",
    "else:\n",
    "    print(\"Layer 'stage4_unit1_relu1' not found in the model.\")\n",
    "# Add a GlobalAveragePooling3D layer\n",
    "x = GlobalAveragePooling3D()(model.output)\n",
    "\n",
    "# Add the output layer with softmax activation for classification\n",
    "num_classes = 1  # Adjust based on your classification task\n",
    "output_tensor = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "# Create the new model with the added output layer\n",
    "model = Model(inputs=model.input, outputs=output_tensor)\n",
    "model.load_weights('../weights_resnet50_aneu_xxl_ep23.h5')# Stenosis weights_resnet50_steno_xxl_seg_ep25\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0003)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "# Use SparseCategoricalCrossentropy loss function\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53af950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "def reconstruct_3d_shape(data_folder, model, stride, num_images=17):\n",
    "    reconstructed_shapes = []\n",
    "    print(\"Processing data from:\", data_folder)\n",
    "    # Counter to keep track of the number of processed images\n",
    "    num_processed_images = 0\n",
    "    \n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith('.nii.gz'):\n",
    "            print(filename)\n",
    "            filepath = os.path.join(data_folder, filename)\n",
    "            img = nib.load(filepath)\n",
    "            image_data = img.get_fdata()\n",
    "            \n",
    "            # Get the shape of the image\n",
    "            image_shape = image_data.shape\n",
    "            \n",
    "            # Calculate the number of boxes along each dimension\n",
    "            num_boxes_x = (image_shape[0] - 32) // stride + 1\n",
    "            num_boxes_y = (image_shape[1] - 32) // stride + 1\n",
    "            num_boxes_z = (image_shape[2] - 32) // stride + 1\n",
    "            \n",
    "            # Initialize the reconstructed shape for the current image\n",
    "            reconstructed_shape = np.zeros((num_boxes_x, num_boxes_y, num_boxes_z))\n",
    "    \n",
    "            # Iterate over the image with the specified stride\n",
    "            for i in range(0, image_shape[0] - 32 + 1, stride):\n",
    "                for j in range(0, image_shape[1] - 32 + 1, stride):\n",
    "                    for k in range(0, image_shape[2] - 32 + 1, stride):\n",
    "                        # Extract the current box\n",
    "                        box = image_data[i:i+32, j:j+32, k:k+32]\n",
    "                        box = np.expand_dims(box, axis=0)\n",
    "                        box = np.expand_dims(box, axis=-1)\n",
    "                        # Evaluate the box with the model\n",
    "                        predictions = model.predict(box, verbose=0)\n",
    "                        \n",
    "                        # Store the predictions in the reconstructed shape\n",
    "                        x_idx = i // stride\n",
    "                        y_idx = j // stride\n",
    "                        z_idx = k // stride\n",
    "                        reconstructed_shape[x_idx, y_idx, z_idx] = predictions\n",
    "            \n",
    "            # Append the reconstructed shape to the list\n",
    "            reconstructed_shapes.append(reconstructed_shape)\n",
    "            \n",
    "            # Increment the counter\n",
    "            num_processed_images += 1\n",
    "            \n",
    "            # Break out of the loop if the number of processed images reaches num_images\n",
    "            if num_processed_images == num_images:\n",
    "                break  \n",
    "    return reconstructed_shapes\n",
    "\n",
    "\n",
    "# Define the folders\n",
    "steno_train_folder =\n",
    "healthy_train_folder = \n",
    "stride = 4\n",
    "reconstructed_aneu = reconstruct_3d_shape(steno_train_folder, model, stride)\n",
    "reconstructed_healthy = reconstruct_3d_shape(healthy_train_folder, model, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label\n",
    "def find_patches(image, threshold, min_patch_size):\n",
    "    # Create a copy of the image to avoid modifying the original\n",
    "    image_copy = np.copy(image)\n",
    "\n",
    "    # Apply threshold to identify low-value voxels\n",
    "    image_copy[image_copy >= threshold] = 0\n",
    "    \n",
    "    # Calculate the total number of non-zero values in the image\n",
    "    remaining_non_zero_count = np.count_nonzero(image_copy)\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    x_len, y_len, z_len = image_copy.shape\n",
    "\n",
    "    # Initialize a mask to mark voxels belonging to patches\n",
    "    patch_mask = np.zeros_like(image_copy, dtype=bool)\n",
    "\n",
    "    # Define neighbor offsets\n",
    "    offsets = [(dx, dy, dz) for dx in range(-1, 2) for dy in range(-1, 2) for dz in range(-1, 2) if (dx, dy, dz) != (0, 0, 0)]\n",
    "\n",
    "    # Iterate over each voxel and check neighbors to find patches\n",
    "    for x in range(1, x_len - 1):\n",
    "        for y in range(1, y_len - 1):\n",
    "            for z in range(1, z_len - 1):\n",
    "                if image_copy[x, y, z] > 0:\n",
    "                    # Check if any neighbor is non-zero\n",
    "                    has_non_zero_neighbor = any(image_copy[x + dx, y + dy, z + dz] > 0 for dx, dy, dz in offsets)\n",
    "                    if has_non_zero_neighbor:\n",
    "                        patch_mask[x, y, z] = True\n",
    "\n",
    "    # Perform connected component analysis to find connected regions of non-zero voxels\n",
    "    labeled_mask, num_regions = label(patch_mask)\n",
    "\n",
    "    # Initialize counter for patches\n",
    "    patch_count = 0\n",
    "\n",
    "    # Iterate over each region and check if it meets the minimum patch size requirement\n",
    "    for label_idx in range(1, num_regions + 1):\n",
    "        region_mask = labeled_mask == label_idx\n",
    "        region_size = np.sum(region_mask)\n",
    "        if region_size >= min_patch_size:\n",
    "            patch_count += 1\n",
    "\n",
    "    return patch_count, remaining_non_zero_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reconstructed_images(reconstructed_images,threshold=0.0000046, min_patch_size=13):\n",
    "    counts_list = []\n",
    "    nonzero_counts_list = []\n",
    "    for image in reconstructed_images:\n",
    "        counts, nonzero_counts = find_patches(image,threshold, min_patch_size)\n",
    "        counts_list.append(counts)\n",
    "        nonzero_counts_list.append(nonzero_counts)\n",
    "    return counts_list, nonzero_counts_list\n",
    "\n",
    "def process_lists(lists, threshold):\n",
    "    total_count = sum(lst > threshold for lst in lists)\n",
    "    return total_count\n",
    "\n",
    "\n",
    "aneu_countus,nonzeros_aneu = process_reconstructed_images(reconstructed_aneu)\n",
    "\n",
    "\n",
    "threshold2 = 0.5\n",
    "\n",
    "\n",
    "healthy_countus,nonzeros_healthy = process_reconstructed_images(reconstructed_healthy)\n",
    "\n",
    "aneu_countss = process_lists(aneu_countus, threshold2) #IF 0 then no stenosis or aneurysm found"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
